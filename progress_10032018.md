# Progress report
10-04-2018

## Course
I would like to take all course in first year, so I can focus on research on
second and third year. 
Rationale to take the courses:
- Course related to my research
- Course related to Acoustics (Speech and Hearing)
- Course related to Computing
- Course of study program: Education Program for Leaders in Data Analytics. 

However, some course schedule are 
crash with other courses.
List Course that I want to take:

Term 1-1:
- I225E Statistical Signal Processing (H. Tanaka, 2 Int)
- I119 Statistics for Data Analytics (Akagi,2 Opt)
- I112 Basics of Computer Systems (Yoshitaka, 2 Opt)
- S503 Innovation Theory and Methodology for Total Capability Development (1 int)

Term 1-2:
- I416 Parallel Processing (Inoguchi, 2 Adv)
- K236EJ Basis of Data Analytics (Ho Bao・Dam・Ide, 2 Int) OR Natural Language Processing I (Nguyen, 2 Int)
- I411 Pattern Analysis and Recognition (Kotani, 2 Adv) 

Term 2-1:
- I237E Formal Languages and Automata (Ogawa, 2 Imd)
- I214E System Optimization (M.Kaneko・Hiraishi, 2 Imd)
- K417EJ Data Analytics (Ho Bao・Dam, 2 Opt)

Term 2-2:
- K619E Advanced Data Analytics (Ho Bao・Dam, 2 Opt) OR I645E Human Perceptual Systems and its Models (Unoki, 2 Adv)
- I213E Discrete Signal Processing (Chong, 2 Imd)

Total obtained credit:
- Intermidiete courses: 2 + 1 + 2 + 2 + 2 + 2 = 11 + 2 (internship) = 13 (13*)
- Advanced courses: 2 + 2 = 4 + 6 (dissertation) = 10 (12*)

\* : if OR courses are selected.

## Research
The initial step of my proposed research is (according to my opinion) are database and method.
Here is my proposal.

### Database
I surveyed some databases included commonly used in our lab, emo-db; fuitsu emotional speech etc. 
I found the most current suitable one is [iemocap-db](#reference) [1]. It provides both 
speech and transcription, so I could train this data. This db is also widely used by the community, 
one which similar is that proposed by [Jin et al.](#reference) [2].

### Method
Firs, I will analyze speech and text feature separately. The initial step is how to extract text from speech.
The method I propoosed is [deepspeech](#reference) [3] based on works of Andrew Ng et al. 
Mozilla also developed it, and mozilla's version of deepspeech is one that I want to try. 

## Internship
Is it too early to talk about internship?

## Reference:
1. [C. Busso, M. Bulut, C. Lee, A. Kazemzadeh, E. Mower, S. Kim, J. Chang, S. Lee, and S. Narayanan, "IEMOCAP: Interactive emotional dyadic motion capture database," Journal of Language Resources and Evaluation, vol. 42, no. 4, pp. 335-359, December 2008.](http://sail.usc.edu/iemocap/)
2. [Jin, Q., Li, C., Chen, S., & Wu, H. (2015, April). Speech emotion recognition with acoustic and lexical features. In Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on (pp. 4749-4753). IEEE.](https://ieeexplore.ieee.org/abstract/document/7178872/)
3. [Hannun, A., Case, C., Casper, J., Catanzaro, B., Diamos, G., Elsen, E., ... & Ng, A. Y. (2014). Deep speech: Scaling up end-to-end speech recognition. arXiv preprint arXiv:1412.5567.](https://arxiv.org/abs/1412.5567)
